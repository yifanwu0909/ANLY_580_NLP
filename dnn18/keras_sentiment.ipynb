{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dot, Embedding,Activation, Input, Reshape, Flatten\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models i mport Model\n",
    "import numpy as np\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple sentiment analysis\n",
    "\n",
    "Sentiment analysis is a supervised task: a text (e.g. sentence, tweet) is labeled with a scalar score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tThe Da Vinci Code book is just awesome.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# got this data from a U Mich sentiment analysis kaggle competition\n",
    "sent_fn = \"training.txt\"\n",
    "#format is 1 (positive) or 0 (negative), tab, sentence\n",
    "with open(sent_fn, 'r') as sent_file:\n",
    "    print(sent_file.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1]\n",
      "['The Da Vinci Code book is just awesome.', \"this was the first clive cussler i've ever read, but even books like Relic, and Da Vinci code were more plausible than this.\", 'i liked the Da Vinci Code a lot.']\n",
      "7086\n"
     ]
    }
   ],
   "source": [
    "# the data set is small - read it all\n",
    "labels = []\n",
    "sents = []\n",
    "with open(sent_fn, 'r') as sent_file:\n",
    "    for line in sent_file:\n",
    "        label,sent = line.strip().split('\\t')\n",
    "        labels.append(int(label))\n",
    "        sents.append(sent)\n",
    "        \n",
    "print(labels[:3])\n",
    "print(sents[:3])\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8718600056449337"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_lens = [len(sent.split()) for sent in sents]\n",
    "# we'll take the first 20 tokens because most of our sentences are length 20 or less\n",
    "sent_len = 20\n",
    "sum([l<=sent_len for l in sent_lens])/float(len(sent_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start with the semantic space from our pre-trained, word2vec vectors\n",
    "\n",
    "\"Transfer learning\" means we can take the information we learned from lots of language on the language modeling task, and apply it to this task where data is more scarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 words in vocab\n",
      "(100000, 300) embedding matrix\n"
     ]
    }
   ],
   "source": [
    "#load our word2vec vocabulary and numpy array\n",
    "\n",
    "vocab_fn = \"GoogleNews_100K_vocab.txt\"\n",
    "with open(vocab_fn, 'r') as vfn:\n",
    "    index2word = vfn.read().split('\\n')\n",
    "print(len(index2word),\"words in vocab\")\n",
    "\n",
    "mat_fn = \"GoogleNews_100K.npy\"\n",
    "embedding_mat = np.load(mat_fn)\n",
    "print(embedding_mat.shape,\"embedding matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add NULL (0) and UNK to our vocab\n",
    "lookup_with_unk = {word:i+2 for i,word in enumerate(index2word)}\n",
    "UNK_IND = 1\n",
    "\n",
    "#add null and UNK vectors to our embedding matrix so it still lines up\n",
    "embeddings_with_unk = np.zeros((embedding_mat.shape[0]+2, embedding_mat.shape[1]))\n",
    "embeddings_with_unk[2:] = embedding_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert our task dataset into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X holds our texts, converted to vocabulary indexes\n",
    "X_matrix = np.zeros((len(sents), sent_len), dtype=np.int32)\n",
    "for i,sent in enumerate(sents):\n",
    "    sent_tokens = word_tokenize(sent.strip().lower())\n",
    "    sent_inds = [lookup_with_unk[s] if s in lookup_with_unk else UNK_IND for s in sent_tokens]\n",
    "    sent_inds = sent_inds[:sent_len] #truncate if necessary\n",
    "    X_matrix[i, :len(sent_inds)] = sent_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# y is our targets - here 0 and 1\n",
    "y = np.asarray(labels)\n",
    "\n",
    "#shuffle both\n",
    "rng_state = np.random.get_state()\n",
    "np.random.shuffle(X_matrix)\n",
    "np.random.set_state(rng_state)\n",
    "np.random.shuffle(y)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sent_in (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "word_vec (Embedding)         (None, None, 300)         30000600  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 300)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                42624     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 30,043,769\n",
      "Trainable params: 30,043,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build a simple recurrent network with keras\n",
    "\n",
    "hidden_size = 16 # tune this based on performance - it's pretty small\n",
    "vocab_size,embed_size = embeddings_with_unk.shape\n",
    "\n",
    "#simplest possible model\n",
    "\n",
    "sent_in = Input((None,), dtype=\"int32\", name=\"sent_in\")\n",
    "# load the weights into the model\n",
    "embed_layer = Embedding(vocab_size, embed_size, name=\"word_vec\", weights=[embeddings_with_unk,])\n",
    "sent_embeddings = embed_layer(sent_in)\n",
    "\n",
    "# mask out some of the data during training to make the task harder\n",
    "sent_embeddings = Dropout(0.5)(sent_embeddings)\n",
    "\n",
    "# compose the sequence of words using a recurrent layer\n",
    "sent_avg = LSTM(32)(sent_embeddings)\n",
    "\n",
    "#add a fully-connected layer - in practice, we would want to see whether this actually improves score or not\n",
    "hidden_repr = Dense(hidden_size, activation=\"tanh\")(sent_avg)\n",
    "\n",
    "pred = Dense(1, activation=\"sigmoid\")(hidden_repr)\n",
    "sentiment_model = Model(inputs=[sent_in], outputs=[pred,])\n",
    "sentiment_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5668 samples, validate on 1418 samples\n",
      "Epoch 1/2\n",
      "5668/5668 [==============================] - 166s 29ms/step - loss: 0.2307 - acc: 0.8943 - val_loss: 0.0594 - val_acc: 0.9866\n",
      "Epoch 2/2\n",
      "5668/5668 [==============================] - 127s 22ms/step - loss: 0.0418 - acc: 0.9876 - val_loss: 0.0401 - val_acc: 0.9873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a503a58d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.fit(X_matrix,y, epochs=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decode model - create the X\n",
    "sample_sents = [\"I love my dog\", \"I'm sick of eating baby carrots\", \"What's the weather tomorrow\"]\n",
    "sample_X = np.zeros((len(sample_sents), sent_len), dtype=np.int32)\n",
    "for i,sent in enumerate(sample_sents):\n",
    "    sent_tokens = sent.strip().lower().split() #lazy tokenization\n",
    "    sent_inds = [lookup_with_unk[s] if s in lookup_with_unk else UNK_IND for s in sent_tokens]\n",
    "    sent_inds = sent_inds[:sent_len] #truncate if necessary\n",
    "    sample_X[i, :len(sent_inds)] = sent_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996\tI love my dog\n",
      "0.00424\tI'm sick of eating baby carrots\n",
      "0.99\tWhat's the weather tomorrow\n"
     ]
    }
   ],
   "source": [
    "# predict the y - how'd we do?\n",
    "predictions = sentiment_model.predict(sample_X)\n",
    "\n",
    "for i, sample in enumerate(sample_sents):\n",
    "    print(\"{:.03}\\t{}\".format(predictions[i][0], sample))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
